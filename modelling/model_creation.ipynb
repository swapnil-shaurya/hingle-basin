{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join, dirname\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = dirname(getcwd())\n",
    "path = join(path, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(join(path, \"completion.csv\")).drop(['Unnamed: 0', 'pump rate (cubic feet/min)','proppant weight (lbs)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[\"easting\", \"northing\"]]\n",
    "y = data.drop([\"easting\", \"northing\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "train_data = [y_train[x] for x in y_train.columns]\n",
    "test_data = [y_test[x] for x in y_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_forest():\n",
    "    return RandomForestRegressor()\n",
    "def create_bagging():\n",
    "    return BaggingRegressor()\n",
    "\n",
    "def create_boosting():\n",
    "    return GradientBoostingRegressor()\n",
    "\n",
    "def create_perceptron():\n",
    "    return MLPRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [create_forest, create_bagging, create_boosting]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdef print_scores(model, train_x, train_y, test_x, test_y, output=True):\n",
    "    train_score = model.score(train_x, train_y)\n",
    "    test_score = model.score(test_x, test_y)\n",
    "    if output:\n",
    "        print(\"Training: {}\".format(train_score))\n",
    "        print(\"Testing: {}\".format(test_score))\n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "porosity \n",
      "\n",
      "RandomForestRegressor()\n",
      "Training: 0.9546055299382701\n",
      "Testing: 0.6810667953166563\n",
      "\n",
      "\n",
      "BaggingRegressor()\n",
      "Training: 0.9409568151441846\n",
      "Testing: 0.6611728853991392\n",
      "\n",
      "\n",
      "GradientBoostingRegressor()\n",
      "Training: 0.7332538045586356\n",
      "Testing: 0.7253005308093994\n",
      "\n",
      "\n",
      "---------\n",
      "---------\n",
      "permeability \n",
      "\n",
      "RandomForestRegressor()\n",
      "Training: 0.9484920535617455\n",
      "Testing: 0.6455653918010315\n",
      "\n",
      "\n",
      "BaggingRegressor()\n",
      "Training: 0.9325695836992649\n",
      "Testing: 0.6222445097530629\n",
      "\n",
      "\n",
      "GradientBoostingRegressor()\n",
      "Training: 0.6880616475070405\n",
      "Testing: 0.6804454768339836\n",
      "\n",
      "\n",
      "---------\n",
      "---------\n",
      "Poisson's ratio \n",
      "\n",
      "RandomForestRegressor()\n",
      "Training: 0.9999644745807965\n",
      "Testing: 0.9997774022990471\n",
      "\n",
      "\n",
      "BaggingRegressor()\n",
      "Training: 0.9999478469809303\n",
      "Testing: 0.9997407509521802\n",
      "\n",
      "\n",
      "GradientBoostingRegressor()\n",
      "Training: 0.9573936559930271\n",
      "Testing: 0.9550340240396877\n",
      "\n",
      "\n",
      "---------\n",
      "---------\n",
      "Young's Modulus \n",
      "\n",
      "RandomForestRegressor()\n",
      "Training: 0.9999820319353482\n",
      "Testing: 0.9998862383813243\n",
      "\n",
      "\n",
      "BaggingRegressor()\n",
      "Training: 0.9999723961670515\n",
      "Testing: 0.9998825426324697\n",
      "\n",
      "\n",
      "GradientBoostingRegressor()\n",
      "Training: 0.963431467993214\n",
      "Testing: 0.9619807809772019\n",
      "\n",
      "\n",
      "---------\n",
      "---------\n",
      "water saturation \n",
      "\n",
      "RandomForestRegressor()\n",
      "Training: 0.9999844072273653\n",
      "Testing: 0.9998936817817972\n",
      "\n",
      "\n",
      "BaggingRegressor()\n",
      "Training: 0.9999714366782828\n",
      "Testing: 0.999869416012995\n",
      "\n",
      "\n",
      "GradientBoostingRegressor()\n",
      "Training: 0.9680620636733014\n",
      "Testing: 0.9659776395102423\n",
      "\n",
      "\n",
      "---------\n",
      "---------\n",
      "oil saturation \n",
      "\n",
      "RandomForestRegressor()\n",
      "Training: 0.9999823600206093\n",
      "Testing: 0.9998965988917111\n",
      "\n",
      "\n",
      "BaggingRegressor()\n",
      "Training: 0.9999691728754171\n",
      "Testing: 0.9998732323906745\n",
      "\n",
      "\n",
      "GradientBoostingRegressor()\n",
      "Training: 0.9680620636733015\n",
      "Testing: 0.9659776395102424\n",
      "\n",
      "\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "good_models = []\n",
    "for i in range(len(train_data)):\n",
    "    max_score = -99999999\n",
    "    print(\"---------\")\n",
    "    print(y.columns[i], \"\\n\")\n",
    "\n",
    "    for model in models:\n",
    "        current_model = model().fit(X_train, train_data[i])\n",
    "        print(current_model)\n",
    "        (train, test) = print_scores(current_model, X_train, train_data[i], X_test, test_data[i])\n",
    "        if test > max_score:\n",
    "            best_model = current_model\n",
    "            max_score = test\n",
    "        print(\"\\n\")\n",
    "    good_models.append(best_model)\n",
    "    print(\"---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "porosity, model: GradientBoostingRegressor()\n",
      "train score: 0.7332538045586356, test score: 0.7253005308093994\n",
      "\n",
      "permeability, model: GradientBoostingRegressor()\n",
      "train score: 0.6880616475070405, test score: 0.6804454768339836\n",
      "\n",
      "Poisson's ratio, model: RandomForestRegressor()\n",
      "train score: 0.9999644745807965, test score: 0.9997774022990471\n",
      "\n",
      "Young's Modulus, model: RandomForestRegressor()\n",
      "train score: 0.9999820319353482, test score: 0.9998862383813243\n",
      "\n",
      "water saturation, model: RandomForestRegressor()\n",
      "train score: 0.9999844072273653, test score: 0.9998936817817972\n",
      "\n",
      "oil saturation, model: RandomForestRegressor()\n",
      "train score: 0.9999823600206093, test score: 0.9998965988917111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_data)):\n",
    "    current_model = good_models[i]\n",
    "    train, test = print_scores(current_model, X_train, train_data[i], X_test, test_data[i], output=False)\n",
    "    print(\"{}, model: {}\".format(train_data[i].name, current_model))\n",
    "    print(\"train score: {}, test score: {}\".format(train, test), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using joblib since it handles np arrays better than pickle\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = join(getcwd(), 'models')\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    dump(good_models[i], join(model_path, train_data[i].name + '.model'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
